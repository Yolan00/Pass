{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FJJyrX9hjo3JoXW9R1U8kBm4eweUJr6Y",
      "authorship_tag": "ABX9TyPqPKB1Rblw5NL3vaXI4/UD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yolan00/Pass/blob/main/ICP_Code%202023_Asil_Simone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PART 0 / DATA UPLOAD ----------------------------------------------------------\n",
        "\n",
        "from google.colab import files  # Library used to upload files.\n",
        "\n",
        "uploaded = files.upload()  # Upload CORPUS.zip\n",
        "\n",
        "!unzip CORPUS.zip\n",
        "! mkdir RESULTS"
      ],
      "metadata": {
        "id": "ddhZQnO0OnLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGFebALPIEGB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "#PART 1 / DATA READING AND SETUP ------------------------------------------------------------------------------------------\n",
        "\n",
        "# read poems from folder\n",
        "def read_poems(folder_path):\n",
        "    poems = []  #Initializes an empty list. This list will be used to store the contents of each poem read from the files.\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith(\".txt\"):  #Check .txt extension\n",
        "            with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as file: #Open the text in read mode with UTF-8 encoding\n",
        "                poems.append(file.read()) #Read content of the file and appends it to the \"poems\" list\n",
        "    return poems\n",
        "\n",
        "# Paths to the folders for each heteronym\n",
        "ricardo_reis_path = \"/content/CORPUS/recardo reis\"\n",
        "alvaro_campos_path = \"/content/CORPUS/alvaro de campos\"\n",
        "alberto_caeiro_path = \"/content/CORPUS/alberto caeiro\"\n",
        "carlos_drummond_path = \"/content/CORPUS/carlos drummond\"\n",
        "\n",
        "# Read poems for each heteronym\n",
        "ricardo_reis_poems = read_poems(ricardo_reis_path)\n",
        "alvaro_campos_poems = read_poems(alvaro_campos_path)\n",
        "alberto_caeiro_poems = read_poems(alberto_caeiro_path)\n",
        "carlos_drummond_poems = read_poems(carlos_drummond_path)\n",
        "\n",
        "# Create a list of titles for each poem based on the heteronym\n",
        "ricardo_reis_titles = [f\"{file_name}\" for file_name in os.listdir(ricardo_reis_path) if file_name.endswith(\".txt\")]\n",
        "alvaro_campos_titles = [f\"{file_name}\" for file_name in os.listdir(alvaro_campos_path) if file_name.endswith(\".txt\")]\n",
        "alberto_caeiro_titles = [f\"{file_name}\" for file_name in os.listdir(alberto_caeiro_path) if file_name.endswith(\".txt\")]\n",
        "carlos_drummond_titles = [f\"{file_name}\" for file_name in os.listdir(carlos_drummond_path) if file_name.endswith(\".txt\")]\n",
        "\n",
        "# Combine all poems, heteronyms, and titles\n",
        "all_poems = ricardo_reis_poems + alvaro_campos_poems + alberto_caeiro_poems + carlos_drummond_poems\n",
        "all_heteronyms = ['Ricardo Reis', 'Álvaro de Campos','Alberto Caeiro', 'carlos_drummond']\n",
        "all_poem_titles = ricardo_reis_titles + alvaro_campos_titles + alberto_caeiro_titles + carlos_drummond_titles\n",
        "\n",
        "#PART 2 / CORE STYLOMETRIC ANALYSIS -----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# List of Portuguese stop words\n",
        "portuguese_stop_words = [\n",
        "    \"a\", \"à\", \"agora\", \"ainda\", \"algo\", \"algumas\", \"alguns\", \"ampla\", \"amplas\", \"amplo\", \"amplos\",\n",
        "    \"aquela\", \"aquelas\", \"aquele\", \"aqueles\", \"aqui\", \"aquilo\", \"as\", \"às\", \"assim\", \"atrás\", \"bem\",\n",
        "    \"boa\", \"boas\", \"bom\", \"bons\", \"breve\", \"cá\", \"cada\", \"cerca\", \"com\", \"como\", \"contra\", \"contudo\",\n",
        "    \"da\", \"daquele\", \"daqueles\", \"das\", \"de\", \"dela\", \"delas\", \"dele\", \"deles\", \"depois\", \"desde\",\n",
        "    \"desta\", \"destas\", \"deste\", \"deste\", \"destes\", \"deve\", \"devem\", \"devendo\", \"dever\", \"deverá\",\n",
        "    \"deverão\", \"deveria\", \"deveriam\", \"devia\", \"deviam\", \"disse\", \"disso\", \"disto\", \"diz\", \"dizem\",\n",
        "    \"dizer\", \"do\", \"dos\", \"e\", \"é\", \"ela\", \"elas\", \"ele\", \"eles\", \"em\", \"enquanto\", \"entre\", \"era\",\n",
        "    \"essa\", \"essas\", \"esse\", \"esses\", \"esta\", \"está\", \"estão\", \"estas\", \"estava\", \"estavam\", \"este\",\n",
        "    \"este\", \"estes\", \"eu\", \"fará\", \"faz\", \"fazer\", \"fazia\", \"fez\", \"fim\", \"foi\", \"for\", \"foram\",\n",
        "    \"forem\", \"fosse\", \"fossem\", \"grande\", \"grandes\", \"há\", \"isso\", \"isto\", \"já\", \"la\", \"lá\", \"lhe\",\n",
        "    \"lhe\", \"lo\", \"mas\", \"me\", \"mesmo\", \"meu\", \"meus\", \"minha\", \"minhas\", \"muito\", \"muitos\", \"na\",\n",
        "    \"não\", \"nas\", \"nem\", \"nenhum\", \"nenhuma\", \"neste\", \"no\", \"nos\", \"nós\", \"nossa\", \"nossas\", \"nosso\",\n",
        "    \"nossos\", \"num\", \"numa\", \"nunca\", \"o\", \"os\", \"ou\", \"para\", \"pela\", \"pelas\", \"pelo\", \"pelos\",\n",
        "    \"pequena\", \"pequenas\", \"pequeno\", \"pequenos\", \"per\", \"perante\", \"pode\", \"podendo\", \"poder\",\n",
        "    \"poderá\", \"poderão\", \"podia\", \"podiam\", \"pôde\", \"pôr\", \"põe\", \"por\", \"porque\", \"posso\", \"pouca\",\n",
        "    \"poucas\", \"pouco\", \"poucos\", \"primeiro\", \"primeiros\", \"própria\", \"próprias\", \"próprio\", \"próprios\",\n",
        "    \"quais\", \"qual\", \"quando\", \"quanto\", \"quantos\", \"que\", \"quem\", \"são\", \"se\", \"seja\", \"sejam\",\n",
        "    \"sem\", \"sempre\", \"sendo\", \"será\", \"serão\", \"seria\", \"seriam\", \"só\", \"sob\", \"sobre\", \"sua\", \"suas\",\n",
        "    \"talvez\", \"também\", \"tampouco\", \"te\", \"tem\", \"temos\", \"tenha\", \"ter\", \"terá\", \"terão\", \"teria\",\n",
        "    \"teriam\", \"teu\", \"teus\", \"teve\", \"ti\", \"tido\", \"tinha\", \"tinham\", \"toda\", \"todas\", \"todo\", \"todos\",\n",
        "    \"tu\", \"tua\", \"tuas\", \"tudo\", \"último\", \"últimos\", \"um\", \"uma\", \"umas\", \"uns\", \"vendo\", \"ver\", \"vez\",\n",
        "    \"vezes\", \"vindo\", \"vir\", \"vos\", \"vós\"\n",
        "]\n",
        "\n",
        "# TF-IDF  (Term Frequency-Inverse Document Frequency) vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words=portuguese_stop_words, lowercase=True)  #Matrix\n",
        "tfidf_matrix = vectorizer.fit_transform(all_poems)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Perform hierarchical clustering\n",
        "linkage_matrix = linkage(cosine_sim, method='ward')\n",
        "\n",
        "# Dendrogram construction\n",
        "plt.figure(figsize=(17, 10))\n",
        "\n",
        "dendrogram(\n",
        "    linkage_matrix,\n",
        "    labels=all_poem_titles,  # Use the titles of the poems\n",
        "    leaf_rotation=90,\n",
        "    leaf_font_size=10,\n",
        "    above_threshold_color='black',\n",
        "    no_labels=False,  # Display labels\n",
        "    orientation='top',  # Display the dendrogram from top to bottom\n",
        "    color_threshold=np.inf,  # Set color_threshold to infinity to prevent automatic color assignment\n",
        "    link_color_func=lambda k: 'black',  # Manually set link colors to black\n",
        ")\n",
        "\n",
        "# Get the axes of the current figure for customization and manipulation of the plot\n",
        "ax = plt.gca()\n",
        "\n",
        "# Extract the x-tick labels for labels color change\n",
        "xtick_labels = ax.get_xticklabels()\n",
        "\n",
        "# Define a color map as a dictionary\n",
        "# This maps each author's name to a specific color\n",
        "color_map = {\n",
        "    'Ricardo Reis': 'green',\n",
        "    'Álvaro de Campos': 'orange',\n",
        "    'Alberto Caeiro': 'blue',\n",
        "    'carlos_drummond': 'purple'\n",
        "}\n",
        "\n",
        "# Initialize an empty dictionary to map each poem title to its author's color\n",
        "all_titles_color_map = {}\n",
        "\n",
        "# Update the dictionary with the color for each title based on the author.\n",
        "# This is done for each set of titles belonging to each author.\n",
        "all_titles_color_map.update({title: color_map['Ricardo Reis'] for title in ricardo_reis_titles})\n",
        "all_titles_color_map.update({title: color_map['Álvaro de Campos'] for title in alvaro_campos_titles})\n",
        "all_titles_color_map.update({title: color_map['Alberto Caeiro'] for title in alberto_caeiro_titles})\n",
        "all_titles_color_map.update({title: color_map['carlos_drummond'] for title in carlos_drummond_titles})\n",
        "\n",
        "# Iterate over each x-tick label on the plot\n",
        "for label in xtick_labels:\n",
        "    # Extract the text of the label (poem title)\n",
        "    title = label.get_text()\n",
        "    # Set the color of the label based on the corresponding author's color in all_titles_color_map\n",
        "    # If the title is not in the map, default to black\n",
        "    label.set_color(all_titles_color_map.get(title, 'black'))\n",
        "\n",
        "\n",
        "plt.title('Phylogenetic Tree with Specific Colors for every author') #Title of the plot\n",
        "plt.savefig(\"/content/RESULTS/Phylogenetic Tree with Specific Colors for every author\", bbox_inches='tight') #Save the plot to our RESULTS path with a tight bounding box\n",
        "plt.show() #Display the plot\n",
        "\n",
        "\n",
        "#PART 3 / ADDITIONAL ANALYSIS FUNCTIONS ------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Function to count most frequent words and save as a text file\n",
        "def count_and_save_most_frequent_words(poems, output_file, stop_words=None, top_n=50):\n",
        "    # Combine all poems into a single string for analysis\n",
        "    all_poems = ' '.join(poems)\n",
        "\n",
        "    # Tokenize the combined string into words and convert to lowercase\n",
        "    words = all_poems.lower().split()\n",
        "\n",
        "    # Remove stop words\n",
        "    if stop_words:\n",
        "        words = [word for word in words if word not in portuguese_stop_words]\n",
        "\n",
        "    # Count the frequency of each word\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    # Get the top N most frequent words\n",
        "    top_words = dict(word_counts.most_common(top_n))\n",
        "\n",
        "    # Save the list of most frequent words to a text file\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        for word, count in top_words.items():\n",
        "            file.write(f\"{word}: {count}\\n\")\n",
        "\n",
        "    return top_words\n",
        "\n",
        "# Function to visualize most frequent words using WordCloud and save as an image\n",
        "def visualize_most_frequent_words(word_counts, heteronym_name, output_image_path):\n",
        "    # Create a WordCloud object\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear') # Display the word cloud image with bilinear interpolation for smoothing\n",
        "    plt.axis('off') # Turn off the axes to only display the word cloud\n",
        "    plt.title(f\"Most Frequent Words for {heteronym_name}\") # Plot title\n",
        "    plt.savefig(output_image_path, bbox_inches='tight') # Save the figure as an image file\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# function that calculates the ratio of the stop words for each heteronym\n",
        "def stop_words_ratio(poems, portuguese_stop_words):\n",
        "    # Combine all poems into a single string for analysis\n",
        "    all_poems = ' '.join(poems)\n",
        "\n",
        "    # Tokenize the combined string into words and convert to lowercase\n",
        "    words = all_poems.lower().split()\n",
        "\n",
        "    # Count the total number of words\n",
        "    total_words = len(words)\n",
        "\n",
        "    # Count the number of stop words\n",
        "    stop_words_count = sum(1 for word in words if word in portuguese_stop_words)\n",
        "\n",
        "    # Calculate the ratio\n",
        "    ratio = stop_words_count / total_words\n",
        "    return ratio\n",
        "\n",
        "# calculates the ratio of unique words out of all words\n",
        "def calculate_average_lexical_density(poems):\n",
        "    total_unique_words = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for poem in poems:\n",
        "        # Tokenize the poem into words and convert to lowercase\n",
        "        words = poem.lower().split()\n",
        "\n",
        "        # Calculate the number of unique words\n",
        "        unique_words = set(words)\n",
        "\n",
        "        # Update totals\n",
        "        total_unique_words += len(unique_words)\n",
        "        total_words += len(words)\n",
        "\n",
        "    # Calculate the overall lexical density ratio\n",
        "    if total_words == 0:\n",
        "        return 0  # Avoid division by zero\n",
        "\n",
        "    average_lexical_density = total_unique_words / total_words\n",
        "    return average_lexical_density\n",
        "\n",
        "def calculate_average_word_length(poems):\n",
        "    # Initialize counters for the total length of all words and the total word count\n",
        "    total_length = 0\n",
        "    word_count = 0\n",
        "\n",
        "    # Iterate through each poem in the collection\n",
        "    for poem in poems:\n",
        "        # Split the poem into individual words\n",
        "        words = poem.split()\n",
        "        # Add the total number of characters in each word to total_length\n",
        "        total_length += sum(len(word) for word in words)\n",
        "        # Increment the total word count by the number of words in the current poem\n",
        "        word_count += len(words)\n",
        "\n",
        "    average_word_length = total_length / word_count if word_count else 0 # If word_count is zero, avoid division by zero by returning 0\n",
        "    return average_word_length\n",
        "\n",
        "\n",
        "# PART 4 / ADDITIONAL ANALYSIS OUTPUT ----------------------------------------------------------------------------------------\n",
        "\n",
        "# Output file paths for saving most frequent words and images\n",
        "output_file_ricardo_reis = \"/content/RESULTS/ricardo_reis_top_words.txt\"\n",
        "output_image_ricardo_reis = \"/content/RESULTS/ricardo_reis_wordcloud.png\"\n",
        "\n",
        "output_file_alvaro_campos = \"/content/RESULTS/alvaro_campos_top_words.txt\"\n",
        "output_image_alvaro_campos = \"/content/RESULTS/alvaro_campos_wordcloud.png\"\n",
        "\n",
        "output_file_alberto_caeiro = \"/content/RESULTS/alberto_caeiro_top_words.txt\"\n",
        "output_image_alberto_caeiro = \"/content/RESULTS/alberto_caeiro_wordcloud.png\"\n",
        "\n",
        "output_file_carlos_drummond = \"/content/RESULTS/carlos_drummond_top_words.txt\"\n",
        "output_image_carlos_drummond = \"/content/RESULTS/carlos_drummond_wordcloud.png\"\n",
        "\n",
        "# Count and save most frequent words for each heteronym\n",
        "ricardo_reis_top_words = count_and_save_most_frequent_words(ricardo_reis_poems, output_file_ricardo_reis, portuguese_stop_words)\n",
        "alvaro_campos_top_words = count_and_save_most_frequent_words(alvaro_campos_poems, output_file_alvaro_campos, portuguese_stop_words)\n",
        "alberto_caeiro_top_words = count_and_save_most_frequent_words(alberto_caeiro_poems, output_file_alberto_caeiro, portuguese_stop_words)\n",
        "carlos_drummond_top_words = count_and_save_most_frequent_words(carlos_drummond_poems, output_file_carlos_drummond, portuguese_stop_words)\n",
        "\n",
        "# Visualize most frequent words for each heteronym and save as images\n",
        "visualize_most_frequent_words(ricardo_reis_top_words, \"Ricardo Reis\", output_image_ricardo_reis)\n",
        "visualize_most_frequent_words(alvaro_campos_top_words, \"Álvaro de Campos\", output_image_alvaro_campos)\n",
        "visualize_most_frequent_words(alberto_caeiro_top_words, \"Alberto Caeiro\", output_image_alberto_caeiro)\n",
        "visualize_most_frequent_words(carlos_drummond_top_words, \"carlos_drummond\", output_image_carlos_drummond)\n",
        "\n",
        "# Stop words ratio calculation\n",
        "stop_words_ratio_reis = stop_words_ratio(ricardo_reis_poems, portuguese_stop_words)\n",
        "stop_words_ratio_alvaro = stop_words_ratio(alvaro_campos_poems, portuguese_stop_words)\n",
        "stop_words_ratio_alberto = stop_words_ratio(alberto_caeiro_poems, portuguese_stop_words)\n",
        "stop_words_ratio_drimmond = stop_words_ratio(carlos_drummond_poems, portuguese_stop_words)\n",
        "\n",
        "# print the stop words ratio\n",
        "print(\"\\n\\nSTOP WORDS TO MAIN WORDS RATIO\")\n",
        "print(\"\\nRicardo Reis:\", round(stop_words_ratio_reis, 2))\n",
        "print(\"\\nÁlvaro de Campos:\", round(stop_words_ratio_alvaro, 2))\n",
        "print(\"\\nAlberto Caeiro:\", round(stop_words_ratio_alberto, 2))\n",
        "print(\"\\ncarlos_drummond:\", round(stop_words_ratio_drimmond, 2))\n",
        "\n",
        "# lexical density calculation\n",
        "ricardo_reis_average_density = calculate_average_lexical_density(ricardo_reis_poems)\n",
        "alvaro_campos_average_density = calculate_average_lexical_density(alvaro_campos_poems)\n",
        "alberto_caeiro_average_density = calculate_average_lexical_density(alberto_caeiro_poems)\n",
        "carlos_drummond_average_density = calculate_average_lexical_density(carlos_drummond_poems)\n",
        "\n",
        "# Print the density results\n",
        "print(\"\\n\\nAVG LEXICAL DENSITY\")\n",
        "print(\"\\nRicardo Reis:\", round(ricardo_reis_average_density, 2))\n",
        "print(\"\\nÁlvaro de Campos:\", round(alvaro_campos_average_density, 2))\n",
        "print(\"\\nAlberto Caeiro:\", round(alberto_caeiro_average_density, 2))\n",
        "print(\"\\nCarlos Drummond:\", round(carlos_drummond_average_density, 2))\n",
        "\n",
        "# Avg word lenght calculation\n",
        "avg_word_length_reis = calculate_average_word_length(ricardo_reis_poems)\n",
        "avg_word_length_alvaro = calculate_average_word_length(alvaro_campos_poems)\n",
        "avg_word_length_alberto = calculate_average_word_length(alberto_caeiro_poems)\n",
        "avg_word_length_carlos = calculate_average_word_length(carlos_drummond_poems)\n",
        "\n",
        "# Print avg word lenght\n",
        "print(\"\\n\\nAVG WORD LENGHT\")\n",
        "print(\"\\nRicardo Reis:\", round(avg_word_length_reis, 2))\n",
        "print(\"\\nÁlvaro de Campos:\", round(avg_word_length_alvaro, 2))\n",
        "print(\"\\nAlberto Caeiro:\", round(avg_word_length_alberto, 2))\n",
        "print(\"\\nCarlos Drummond:\", round(avg_word_length_carlos, 2))"
      ]
    }
  ]
}